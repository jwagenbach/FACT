{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from captum.attr import GradientShap, IntegratedGradients, Saliency\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, Subset\n",
    "from torchvision import transforms\n",
    "\n",
    "form\n",
    "from lfxai.models.images import ClassifierMnist, EncoderMnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "torch.random.manual_seed(123)\n",
    "batch_size = 128\n",
    "\n",
    "# Model Args\n",
    "image_height = 28\n",
    "dim_latent = 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data loading\n",
    "data_dir = \"data/mnist\"\n",
    "shared_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = MNIST(data_dir, train=True, download=True, transform=shared_transform\n",
    "                                           )\n",
    "test_dataset = MNIST(data_dir, train=False, download=True, transform=shared_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Model loading ######\n",
    "# Specification\n",
    "dim_latent = 4\n",
    "name = \"TestClassifier\"\n",
    "classifier_state_dict_path = os.path.join('')\n",
    "\n",
    "# Load\n",
    "encoder = EncoderMnist(dim_latent)\n",
    "classifier = ClassifierMnist(encoder, dim_latent, name)\n",
    "classifier.load_state_dict(torch.load(classifier_state_dict_path), strict=True)\n",
    "\n",
    "print(\"Classifier Loaded\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Instantiate GradShap For Encoder and Full Model\n",
    "# Note this code is directly from Captum\n",
    "gradshap_encoder = GradientShap(encoder)\n",
    "gradshap_full_model = GradientShap(classifier)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
